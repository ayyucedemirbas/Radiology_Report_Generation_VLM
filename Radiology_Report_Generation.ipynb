{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array"
      ],
      "metadata": {
        "id": "HNQYaAWcqOM_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkVckzsBrjp5",
        "outputId": "804f3cb2-977a-47a0-d834-599370c7cc79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-24 20:11:57--  https://openi.nlm.nih.gov/imgs/collections/NLMCXR_png.tgz\n",
            "Resolving openi.nlm.nih.gov (openi.nlm.nih.gov)... 130.14.65.157, 2607:f220:41e:7065::157\n",
            "Connecting to openi.nlm.nih.gov (openi.nlm.nih.gov)|130.14.65.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1360814128 (1.3G) [application/x-gzip]\n",
            "Saving to: ‘NLMCXR_png.tgz’\n",
            "\n",
            "NLMCXR_png.tgz      100%[===================>]   1.27G  1.99MB/s    in 10m 54s \n",
            "\n",
            "2025-01-24 20:22:51 (1.99 MB/s) - ‘NLMCXR_png.tgz’ saved [1360814128/1360814128]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sBaWvCZuSWE",
        "outputId": "9ce1b5af-e038-4ae5-fc6e-573746c4d51a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-24 20:22:51--  https://openi.nlm.nih.gov/imgs/collections/NLMCXR_reports.tgz\n",
            "Resolving openi.nlm.nih.gov (openi.nlm.nih.gov)... 130.14.65.157, 2607:f220:41e:7065::157\n",
            "Connecting to openi.nlm.nih.gov (openi.nlm.nih.gov)|130.14.65.157|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1112632 (1.1M) [application/x-gzip]\n",
            "Saving to: ‘NLMCXR_reports.tgz’\n",
            "\n",
            "NLMCXR_reports.tgz  100%[===================>]   1.06M  1.26MB/s    in 0.8s    \n",
            "\n",
            "2025-01-24 20:22:52 (1.26 MB/s) - ‘NLMCXR_reports.tgz’ saved [1112632/1112632]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir workdir"
      ],
      "metadata": {
        "id": "V44khsSww0Qm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd workdir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUZEBu63w3r4",
        "outputId": "0308fced-7bc1-4f57-93cb-510aee7898c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/workdir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xvzf /content/NLMCXR_png.tgz -C .\n",
        "!tar -xvzf /content/NLMCXR_reports.tgz -C ."
      ],
      "metadata": {
        "id": "jInhjBdgqQYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDpLM8qkz7YT",
        "outputId": "f11295fd-8ac3-452f-c6bf-bd90c2b7c2ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET"
      ],
      "metadata": {
        "id": "O5BpJVTszv90"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv workdir/ecgen-radiology ."
      ],
      "metadata": {
        "id": "g0hwrjExz18-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_valid_pairs(image_dir='workdir', report_dir='ecgen-radiology'):\n",
        "    valid_pairs = []\n",
        "    report_files = {}\n",
        "\n",
        "    for root, _, files in os.walk(report_dir):\n",
        "        for f in files:\n",
        "            if f.lower().endswith('.xml'):\n",
        "                base_name = os.path.splitext(f)[0].lower()\n",
        "                report_files[base_name] = os.path.join(root, f)\n",
        "\n",
        "    for root, _, files in os.walk(image_dir):\n",
        "        for f in files:\n",
        "            if f.lower().endswith('.png'):\n",
        "                base_name = os.path.splitext(f)[0].lower()\n",
        "                if base_name in report_files:\n",
        "                    valid_pairs.append((\n",
        "                        os.path.join(root, f),\n",
        "                        report_files[base_name]\n",
        "                    ))\n",
        "    return valid_pairs"
      ],
      "metadata": {
        "id": "J7gc68Q0r5b7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_xml_report(xml_path):\n",
        "    try:\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        ns = {'pmc': 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC'}\n",
        "\n",
        "        findings_elem = root.find(\".//pmc:AbstractText[@Label='FINDINGS']\", ns)\n",
        "        impression_elem = root.find(\".//pmc:AbstractText[@Label='IMPRESSION']\", ns)\n",
        "\n",
        "        findings = findings_elem.text.strip() if (findings_elem is not None and findings_elem.text) else \"\"\n",
        "        impression = impression_elem.text.strip() if (impression_elem is not None and impression_elem.text) else \"\"\n",
        "\n",
        "        if not findings and not impression:\n",
        "            return None\n",
        "\n",
        "        return f\"FINDINGS: {findings}. IMPRESSION: {impression}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {xml_path}: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "Td03WM0W1K9v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "\n",
        "def parse_xml_report(xml_path):\n",
        "    try:\n",
        "        tree = ET.parse(xml_path)\n",
        "        root = tree.getroot()\n",
        "        ns = {'pmc': 'http://www.ncbi.nlm.nih.gov/pmc/articles/PMC'}\n",
        "\n",
        "        findings = root.find(\".//AbstractText[@Label='FINDINGS']\", ns)\n",
        "        impression = root.find(\".//AbstractText[@Label='IMPRESSION']\", ns)\n",
        "\n",
        "        findings_text = findings.text.strip() if (findings is not None and findings.text) else \"\"\n",
        "        impression_text = impression.text.strip() if (impression is not None and impression.text) else \"\"\n",
        "\n",
        "        if not findings_text and not impression_text:\n",
        "            return None, []\n",
        "\n",
        "        image_ids = [img.get('id') for img in root.findall('.//parentImage')]\n",
        "\n",
        "        image_paths = [f\"workdir/{img_id}.png\" for img_id in image_ids]\n",
        "\n",
        "        return (\n",
        "            f\"FINDINGS: {findings_text}. IMPRESSION: {impression_text}\",\n",
        "            image_paths\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing {xml_path}: {str(e)}\")\n",
        "        return None, []\n",
        "\n",
        "def create_dataset():\n",
        "    data = []\n",
        "\n",
        "    for root_dir, _, files in os.walk(\"ecgen-radiology\"):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.xml'):\n",
        "                xml_path = os.path.join(root_dir, file)\n",
        "                report_text, image_paths = parse_xml_report(xml_path)\n",
        "\n",
        "                if report_text and image_paths:\n",
        "                    for img_path in image_paths:\n",
        "                        if os.path.exists(img_path):\n",
        "                            data.append({\n",
        "                                'image_path': img_path,\n",
        "                                'report': report_text\n",
        "                            })\n",
        "                        else:\n",
        "                            print(f\"Missing image: {img_path}\")\n",
        "\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "radiology_df = create_dataset()\n",
        "print(f\"Found {len(radiology_df)} valid image-report pairs\")\n",
        "\n",
        "if not radiology_df.empty:\n",
        "    print(\"\\nSample entry:\")\n",
        "    print(f\"Image path: {radiology_df.iloc[0]['image_path']}\")\n",
        "    print(f\"Report: {radiology_df.iloc[0]['report']}\")\n",
        "else:\n",
        "    print(\"\\nNo valid pairs found. Check:\")\n",
        "    print(\"- XML files in ecgen-radiology directory\")\n",
        "    print(\"- Image files in workdir directory\")\n",
        "    print(\"- File naming consistency between XML and PNG files\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tCW8f1t0oB9",
        "outputId": "d96712c7-485c-4b44-a5e6-ae4affcb8ad9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7430 valid image-report pairs\n",
            "\n",
            "Sample entry:\n",
            "Image path: workdir/CXR839_IM-2363-1001.png\n",
            "Report: FINDINGS: Heart size normal. No pleural effusions or pneumothorax. Lungs are clear. Soft tissues and XXXX are unremarkable.. IMPRESSION: Normal chest.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(\n",
        "    num_words=5000,\n",
        "    oov_token=\"<unk>\",\n",
        "    filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ '\n",
        ")"
      ],
      "metadata": {
        "id": "vthyBwP7qWqH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(radiology_df['report'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = 100  # Increase it for longer reports"
      ],
      "metadata": {
        "id": "EkjNtZZiqiic"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print([word for word in tokenizer.word_index if \"pneumonia\" in word or \"effusion\" in word][:10])"
      ],
      "metadata": {
        "id": "NfID5iWBqkOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np\n",
        "\n",
        "class RadiologyDataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                 dataframe,\n",
        "                 tokenizer,\n",
        "                 batch_size=8,\n",
        "                 image_size=224,\n",
        "                 max_length=100,\n",
        "                 shuffle=True):\n",
        "\n",
        "        self.df = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.image_size = image_size\n",
        "        self.max_length = max_length\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.df) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch_df = self.df.iloc[batch_indexes]\n",
        "\n",
        "        batch_images = []\n",
        "        batch_sequences = []\n",
        "\n",
        "        for _, row in batch_df.iterrows():\n",
        "            img = load_img(row['image_path'], target_size=(self.image_size, self.image_size))\n",
        "            img_array = img_to_array(img) / 255.0\n",
        "            batch_images.append(img_array)\n",
        "\n",
        "            sequence = self.tokenizer.texts_to_sequences([row['report']])[0]\n",
        "            padded_sequence = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "                [sequence], maxlen=self.max_length, padding='post'\n",
        "            )[0]\n",
        "            batch_sequences.append(padded_sequence)\n",
        "\n",
        "        batch_images = np.array(batch_images)\n",
        "        batch_sequences = np.array(batch_sequences)\n",
        "\n",
        "        batch_targets = np.zeros_like(batch_sequences)\n",
        "        batch_targets[:, :-1] = batch_sequences[:, 1:]\n",
        "\n",
        "        return {'input_layer_2': batch_images, 'input_layer_3': batch_sequences}, batch_targets\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def get_sample(self, index=0):\n",
        "        if index >= self.__len__():\n",
        "            index = 0\n",
        "        return self.__getitem__(index)"
      ],
      "metadata": {
        "id": "39d20zz9qqlp"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 224\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "max_length = 100\n",
        "batch_size = 16  # Reduced for Colab memory\n",
        "#vocab_size = 5001\n",
        "#max_length = 50\n",
        "embedding_dim = 256\n",
        "num_heads = 8\n",
        "ff_dim = 512\n",
        "num_transformer_blocks = 4"
      ],
      "metadata": {
        "id": "DxL5owrJrG4R"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_encoder(image_size):\n",
        "    inputs = layers.Input(shape=(image_size, image_size, 3))\n",
        "\n",
        "    patch_size = 16\n",
        "    num_patches = (image_size // patch_size) ** 2\n",
        "    projection_dim = 768\n",
        "\n",
        "    patches = layers.Conv2D(\n",
        "        filters=projection_dim,\n",
        "        kernel_size=patch_size,\n",
        "        strides=patch_size,\n",
        "        padding=\"valid\"\n",
        "    )(inputs)\n",
        "\n",
        "    patches = layers.Reshape((num_patches, projection_dim))(patches)\n",
        "\n",
        "    positional_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)\n",
        "    positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "    encoded_patches = patches + positional_embedding(positions)\n",
        "\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=projection_dim)(x1, x1)\n",
        "        x2 = layers.Add()([x1, attention_output])\n",
        "\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        ffn_output = layers.Dense(ff_dim, activation=\"relu\")(x3)\n",
        "        ffn_output = layers.Dense(projection_dim)(ffn_output)\n",
        "        encoded_patches = layers.Add()([x2, ffn_output])\n",
        "\n",
        "    model = models.Model(inputs, encoded_patches)\n",
        "    return model\n",
        "\n",
        "def create_text_decoder(vocab_size, embedding_dim, max_length):\n",
        "    inputs = layers.Input(shape=(max_length,))\n",
        "\n",
        "    word_embeddings = layers.Embedding(vocab_size, embedding_dim)(inputs)\n",
        "    positional_embeddings = layers.Embedding(max_length, embedding_dim)(tf.range(start=0, limit=max_length, delta=1))\n",
        "    embeddings = word_embeddings + positional_embeddings\n",
        "\n",
        "    x = embeddings\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embedding_dim)(x1, x1)\n",
        "        x2 = layers.Add()([x1, attention_output])\n",
        "\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        ffn_output = layers.Dense(ff_dim, activation=\"relu\")(x3)\n",
        "        ffn_output = layers.Dense(embedding_dim)(ffn_output)\n",
        "        x = layers.Add()([x2, ffn_output])\n",
        "\n",
        "    outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "def create_image_captioning_model(image_size, vocab_size, embedding_dim, max_length):\n",
        "    vit_encoder = create_vit_encoder(image_size)\n",
        "    text_decoder = create_text_decoder(vocab_size, embedding_dim, max_length)\n",
        "\n",
        "    image_inputs = layers.Input(shape=(image_size, image_size, 3), name='input_layer_2')\n",
        "    text_inputs = layers.Input(shape=(max_length,), name='input_layer_3')\n",
        "\n",
        "    encoded_image = vit_encoder(image_inputs)\n",
        "\n",
        "    encoded_image = layers.GlobalAveragePooling1D()(encoded_image)\n",
        "    encoded_image = layers.Dense(embedding_dim, activation=\"relu\")(encoded_image)\n",
        "    encoded_image = layers.RepeatVector(max_length)(encoded_image)\n",
        "\n",
        "\n",
        "    embeddings = layers.Concatenate(axis=2)([encoded_image, text_decoder(text_inputs)])\n",
        "\n",
        "    outputs = layers.Dense(vocab_size, activation=\"softmax\")(embeddings)\n",
        "\n",
        "    model = models.Model(inputs=[image_inputs, text_inputs], outputs=outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "fuj_2hhRrLIZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = RadiologyDataGenerator(\n",
        "    dataframe=radiology_df,\n",
        "    tokenizer=tokenizer,\n",
        "    batch_size=8,\n",
        "    image_size=224,\n",
        "    max_length=100,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "sample_batch = train_generator.get_sample(0)\n",
        "print(\"Batch shapes:\")\n",
        "print(f\"Images: {sample_batch[0]['input_layer_2'].shape}\")\n",
        "print(f\"Sequences: {sample_batch[0]['input_layer_3'].shape}\")\n",
        "print(f\"Targets: {sample_batch[1].shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cld_JZQ74qLl",
        "outputId": "3cb24f49-95ff-43b5-df66-85c33121aafa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shapes:\n",
            "Images: (8, 224, 224, 3)\n",
            "Sequences: (8, 100)\n",
            "Targets: (8, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_image_captioning_model(\n",
        "    image_size=image_size,\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=256,\n",
        "    max_length=max_length\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "QpLFFLGX4vtO"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbdIMmIh4zUi",
        "outputId": "b9ae46c2-44d5-47e0-86f3-cc3a0d4a56a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m795/929\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m42s\u001b[0m 318ms/step - accuracy: 0.6028 - loss: 2.8754"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvOVOV-jp_CI",
        "outputId": "b0401f96-994f-4b92-b56c-a8018114e184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Report:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma mycoplasma\n"
          ]
        }
      ],
      "source": [
        "def generate_radiology_report(model, image_path):\n",
        "    img = load_img(image_path, target_size=(image_size, image_size))\n",
        "    img = img_to_array(img) / 255.0\n",
        "    input_seq = np.zeros((1, max_length))\n",
        "\n",
        "    for i in range(max_length):\n",
        "        pred = model.predict({'input_layer_2': np.expand_dims(img, 0), 'input_layer_3': input_seq})\n",
        "        predicted_id = np.argmax(pred[0, i])\n",
        "        if predicted_id == tokenizer.word_index.get('<end>', -1) or i == max_length-1:\n",
        "            break\n",
        "        input_seq[0, i] = predicted_id\n",
        "\n",
        "    return ' '.join([tokenizer.index_word.get(int(id), '') for id in input_seq[0] if id != 0])\n",
        "\n",
        "test_image = 'abdomen.jpg'\n",
        "print(\"\\nGenerated Report:\")\n",
        "print(generate_radiology_report(model, test_image))"
      ]
    }
  ]
}